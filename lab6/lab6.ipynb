{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn import cluster, datasets, metrics\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_samples = 1500 # no.of.data points \n",
    "\n",
    "# The dataset function is avialable in sklearn package\n",
    "noisy_moons,moon_labels = datasets.make_moons(n_samples=n_samples, noise=.1) # Generate Moon Toy Dataset\n",
    "noisy_circles,circle_labels = datasets.make_circles(n_samples=n_samples, factor=.5, noise=.05) # Generate Circle Toy Dataset\n",
    "\n",
    "noisy_moons.shape\n",
    "moon_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in Array\n",
    "noisy_moons=np.array(noisy_moons)\n",
    "noisy_circles = np.array(noisy_circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Half-moon data\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Half-moon shaped data\", fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.scatter(noisy_moons[:,0],noisy_moons[:,1])\n",
    "plt.savefig('HALF_MOON.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Circle data\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Concentric circles of data points\", fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.scatter(noisy_circles[:,0],noisy_circles[:,1])\n",
    "plt.savefig('CIRCLE.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " k-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells.\n",
    "The problem is computationally difficult (NP-hard); however, efficient heuristic algorithms converge quickly to a local optimum\n",
    "K-means algorithm is very fast (one of the fastest clustering algorithms available), but it falls in local minima. Thatâ€™s why it can be useful to restart it several times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit K-Means Clustering on noise moon data\n",
    "km=cluster.KMeans(n_clusters=2)\n",
    "km.fit(noisy_moons)\n",
    "km.labels_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.202\n",
      "Silhouette Coefficient: 0.490\n"
     ]
    }
   ],
   "source": [
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(moon_labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\"\n",
    "      % metrics.silhouette_score(noisy_moons, km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Half-moon shaped data\", fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.scatter(noisy_moons[:,0],noisy_moons[:,1],c=km.labels_)\n",
    "plt.savefig('CLUSTER_MOON.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit K-Means Clustering on noise Circle data\n",
    "km.fit(noisy_circles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completeness: 0.000\n",
      "Silhouette Coefficient: 0.354\n"
     ]
    }
   ],
   "source": [
    "print(\"Completeness: %0.3f\" % metrics.completeness_score(circle_labels, km.labels_))\n",
    "print(\"Silhouette Coefficient: %0.3f\" % metrics.silhouette_score(noisy_circles, km.labels_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Concentric circles of data points\", fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.scatter(noisy_circles[:,0],noisy_circles[:,1],c=km.labels_)\n",
    "plt.savefig('CLUSTER_CIRCLE.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Disadvanatges of K-Means Clustering\n",
    "\n",
    "##### 1) Difficult to predict K-Value.\n",
    "##### 2) With global cluster, it didn't work well.\n",
    "##### 3) Different initial partitions can result in different final clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Density-based spatial clustering of applications with noise (DBSCAN) is a data clustering algorithm. It is a density-based clustering algorithm: given a set of points in some space, it groups together points that are closely packed together (points with many nearby neighbors), marking as outliers points that lie alone in low-density regions (whose nearest neighbors are too far away)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit DBSCAN Clustering on noise moon data\n",
    "dbs = cluster.DBSCAN(eps=0.1) # The maximum distance between two samples for them to be considered as in the same neighborhood.\n",
    "dbs.fit(noisy_moons)\n",
    "dbs.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Half-moon shaped data\", fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.scatter(noisy_moons[:,0],noisy_moons[:,1],c=dbs.labels_)\n",
    "plt.savefig('DBSCAN_MOON.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit DBSCAN Clustering on noise Circle data\n",
    "dbs.fit(noisy_circles)\n",
    "dbs.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Concentric circles of data points\", fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.scatter(noisy_circles[:,0],noisy_circles[:,1],c=dbs.labels_)\n",
    "plt.savefig('DBSCAN_CIRCLE.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA on Moon Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "scikit_pca = PCA(n_components=2)\n",
    "noisy_moons_spca = scikit_pca.fit_transform(noisy_moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 7))\n",
    "\n",
    "ax[0].scatter(noisy_moons_spca[moon_labels == 0, 0], noisy_moons_spca[moon_labels == 0, 1],\n",
    "              color='red', marker='^', alpha=0.5)\n",
    "ax[0].scatter(noisy_moons_spca[moon_labels == 1, 0], noisy_moons_spca[moon_labels == 1, 1],\n",
    "              color='blue', marker='o', alpha=0.5)\n",
    "\n",
    "ax[1].scatter(noisy_moons_spca[moon_labels == 0, 0], np.zeros((750, 1)) + 0.02,\n",
    "              color='red', marker='^', alpha=0.5)\n",
    "ax[1].scatter(noisy_moons_spca[moon_labels == 1, 0], np.zeros((750, 1)) - 0.02,\n",
    "              color='blue', marker='o', alpha=0.5)\n",
    "\n",
    "ax[0].set_xlabel('PC1')\n",
    "ax[0].set_ylabel('PC2')\n",
    "ax[1].set_ylim([-1, 1])\n",
    "ax[1].set_yticks([])\n",
    "ax[1].set_xlabel('PC1')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('PCA_MOON.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0         1\n",
      "0  1.000000 -0.446104\n",
      "1 -0.446104  1.000000\n"
     ]
    }
   ],
   "source": [
    "# Compute the correlation matrix before doing PCA\n",
    "nm=pd.DataFrame(noisy_moons)\n",
    "pca_corr=nm.corr()\n",
    "print(pca_corr)\n",
    "sns.heatmap(pca_corr, vmax=1, center=0, square=True)\n",
    "plt.savefig('CORR_PCA_Before.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0             1\n",
      "0  1.000000e+00  6.119815e-17\n",
      "1  6.119815e-17  1.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# Compute the correlation matrix after doing PCA\n",
    "nmp=pd.DataFrame(noisy_moons_spca)\n",
    "corr_pca=nmp.corr()\n",
    "print(corr_pca)\n",
    "sns.heatmap(corr_pca, vmax=1, center=0, square=True)\n",
    "plt.savefig('PCA_CORR_After.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import KernelPCA\n",
    "scikit_kpca = KernelPCA(n_components=2, kernel='rbf', gamma=15)\n",
    "noisy_moons_kpca = scikit_kpca.fit_transform(noisy_moons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              0             1\n",
      "0  1.000000e+00  1.643701e-16\n",
      "1  1.643701e-16  1.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# Compute the correlation matrix after doing PCA\n",
    "\n",
    "kmp=pd.DataFrame(noisy_moons_kpca)\n",
    "corr_kpca=kmp.corr()\n",
    "print(corr_kpca)\n",
    "sns.heatmap(corr_kpca, vmax=1, center=0, square=True)\n",
    "plt.savefig('KPCA_CORR.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(noisy_moons_kpca[moon_labels == 0, 0], noisy_moons_kpca[moon_labels == 0, 1],\n",
    "            color='red', marker='^', alpha=0.5)\n",
    "plt.scatter(noisy_moons_kpca[moon_labels == 1, 0], noisy_moons_kpca[moon_labels == 1, 1],\n",
    "            color='blue', marker='o', alpha=0.5)\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "# plt.tight_layout()\n",
    "plt.savefig('PCA_MOON_scatter.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(max_samples=100, contamination = 0.01)\n",
    "clf.fit(noisy_moons)\n",
    "y_pred_train = clf.predict(noisy_moons)\n",
    "\n",
    "pos = y_pred_train > 0\n",
    "neg = y_pred_train < 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# plot the line, the samples, and the nearest vectors to the plane\n",
    "xx, yy = np.meshgrid(np.linspace(min((noisy_moons[:, 0])), max((noisy_moons[:, 0])), 500), np.linspace(min((noisy_moons[:, 1])), max((noisy_moons[:, 1])), 500))\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.title(\"IsolationForest\")\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues_r)\n",
    "\n",
    "b1 = plt.scatter(noisy_moons[pos][:, 0], noisy_moons[pos][:, 1], c='green', edgecolor='k')\n",
    "b2 = plt.scatter(noisy_moons[neg][:, 0], noisy_moons[neg][:, 1], c='red', edgecolor='k')\n",
    "\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.xlim((xx.min(), xx.max()))\n",
    "plt.ylim((yy.min(), yy.max()))\n",
    "\n",
    "plt.savefig('OUTLIER_MOON.png', dpi=300)\n",
    "print(pos.sum())\n",
    "print(neg.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "clf = IsolationForest(max_samples=100, contamination = 0.01)\n",
    "clf.fit(noisy_circles)\n",
    "y_pred_train = clf.predict(noisy_circles)\n",
    "\n",
    "pos = y_pred_train > 0\n",
    "neg = y_pred_train < 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1485\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "# plot the line, the samples, and the nearest vectors to the plane\n",
    "xx, yy = np.meshgrid(np.linspace(min((noisy_circles[:, 0])), max((noisy_circles[:, 0])), 500), \n",
    "                     np.linspace(min((noisy_circles[:, 1])), max((noisy_circles[:, 1])), 500))\n",
    "Z = clf.decision_function(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "\n",
    "plt.title(\"IsolationForest\")\n",
    "plt.contourf(xx, yy, Z, cmap=plt.cm.Blues_r)\n",
    "\n",
    "b1 = plt.scatter(noisy_circles[pos][:, 0], noisy_circles[pos][:, 1], c='green', edgecolor='k')\n",
    "b2 = plt.scatter(noisy_circles[neg][:, 0], noisy_circles[neg][:, 1], c='red', edgecolor='k')\n",
    "\n",
    "plt.axis('tight')\n",
    "\n",
    "plt.xlim((xx.min(), xx.max()))\n",
    "plt.ylim((yy.min(), yy.max()))\n",
    "\n",
    "plt.savefig('OUTLIER_CIRCLE.png', dpi=300)\n",
    "print(pos.sum())\n",
    "print(neg.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering and PCA on wine Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity of ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280/OD315 of diluted wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Class label  Alcohol  Malic acid   Ash  Alcalinity of ash  Magnesium  \\\n",
       "0            1    14.23        1.71  2.43               15.6        127   \n",
       "1            1    13.20        1.78  2.14               11.2        100   \n",
       "2            1    13.16        2.36  2.67               18.6        101   \n",
       "3            1    14.37        1.95  2.50               16.8        113   \n",
       "4            1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total phenols  Flavanoids  Nonflavanoid phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color intensity   Hue  OD280/OD315 of diluted wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "df_wine = pd.read_csv('https://archive.ics.uci.edu/ml/'\n",
    "                      'machine-learning-databases/wine/wine.data',\n",
    "                      header=None)\n",
    "\n",
    "# if the Wine dataset is temporarily unavailable from the\n",
    "# UCI machine learning repository, un-comment the following line\n",
    "# of code to load the dataset from a local path:\n",
    "\n",
    "# df_wine = pd.read_csv('wine.data', header=None)\n",
    "\n",
    "df_wine.columns = ['Class label', 'Alcohol', 'Malic acid', 'Ash',\n",
    "                   'Alcalinity of ash', 'Magnesium', 'Total phenols',\n",
    "                   'Flavanoids', 'Nonflavanoid phenols', 'Proanthocyanins',\n",
    "                   'Color intensity', 'Hue',\n",
    "                   'OD280/OD315 of diluted wines', 'Proline']\n",
    "\n",
    "df_wine.head()\n",
    "#df_wine.to_csv('WindeData.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "Name: Class label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Task 1:\n",
    "# Check the counts of each wine class\n",
    "print(df_wine[\"Class label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Alcohol', 'Malic acid', 'Ash', 'Alcalinity of ash', 'Magnesium',\n",
      "       'Total phenols', 'Flavanoids', 'Nonflavanoid phenols',\n",
      "       'Proanthocyanins', 'Color intensity', 'Hue',\n",
      "       'OD280/OD315 of diluted wines', 'Proline'],\n",
      "      dtype='object')\n",
      "Index(['Class label'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Fetch data into x and y variables\n",
    "x=df_wine.ix[:,1:14] # Covariates or input\n",
    "y=df_wine.ix[:,:1] # Labels or classes or output\n",
    "print(x.columns)\n",
    "print(y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Task 2\n",
    "# Clustering using K Means Algorithm\n",
    "km_wine=cluster.KMeans(n_clusters=3)\n",
    "km_wine.fit(x)\n",
    "\n",
    "#print(\"Completeness: %0.3f\" % metrics.completeness_score(y.values().tolist(), km.labels_))\n",
    "#print(\"Silhouette Coefficient: %0.3f\"\n",
    "      #% metrics.silhouette_score(y., km.labels_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3\n",
    "# Scatter plot data into 3 classes based on True Labels and plot with legends. Hint: use any two variables \n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Wine data\", fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.scatter(x[\"Alcohol\"],x[\"Proline\"],c=y[\"Class label\"])\n",
    "plt.savefig('Wine_plot.png', dpi=300)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 4\n",
    "# Use cluster model labels to group them in predicted classes\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.title(\"Wine data Predict\", fontsize=18)\n",
    "plt.grid(True)\n",
    "plt.scatter(x[\"Alcohol\"],x[\"Proline\"],c=km_wine.labels_)\n",
    "plt.savefig('Wine_plot_predict.png', dpi=300)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we have splitted the data into 70:30 training and test subsets, respectively.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df_wine.iloc[:, 1:].values, df_wine.iloc[:, 0].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    71\n",
      "1    59\n",
      "3    48\n",
      "dtype: int64\n",
      "2    50\n",
      "1    41\n",
      "3    33\n",
      "dtype: int64\n",
      "2    21\n",
      "1    18\n",
      "3    15\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(pd.value_counts(pd.Series(y)))\n",
    "print(pd.value_counts(pd.Series(y_train)))\n",
    "print(pd.value_counts(pd.Series(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardizing the data\n",
    "# Standardize features by removing the mean and scaling to unit variance\n",
    "# The standard score of a sample x is calculated as:\n",
    "# z = (x - u) / s\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction: Principal component analysis using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36951469, 0.18434927, 0.11815159, 0.07334252, 0.06422108,\n",
       "       0.05051724, 0.03954654, 0.02643918, 0.02389319, 0.01629614,\n",
       "       0.01380021, 0.01172226, 0.00820609])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(1, 14), pca.explained_variance_ratio_, alpha=0.5, align='center')\n",
    "plt.step(range(1, 14), np.cumsum(pca.explained_variance_ratio_), where='mid')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "plt.savefig('PCA_WINE.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 5: Apply PCA with n_components=2 on X_train_std data and transform test data accordingly\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first two principal components\n",
    "\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1])\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.savefig('PCA_WINE_ULBL.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of two best principal components using y_train data\n",
    "colors = ['r', 'b', 'g']\n",
    "markers = ['s', 'x', 'o']\n",
    "\n",
    "for l, c, m in zip(np.unique(y_train), colors, markers):\n",
    "    plt.scatter(X_train_pca[y_train == l, 0], \n",
    "                X_train_pca[y_train == l, 1], \n",
    "                c=c, label=l, marker=m)\n",
    "    plt.xlabel('PC 1')\n",
    "    plt.ylabel('PC 2')\n",
    "    plt.legend()\n",
    "    plt.savefig('PCA_WINE_LBL.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.4, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    # plot class samples\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.6, \n",
    "                    c=cmap(idx),\n",
    "                    edgecolor='black',\n",
    "                    marker=markers[idx], \n",
    "                    label=cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Training logistic regression classifier using the first 2 principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test is = 92.592593\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "X_test_pca = pca.transform(X_test_std)\n",
    "\n",
    "# Task 6: Apply Logistic Regression on training features and predict test features\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr = lr.fit(X_train_pca,y_train) # Train a Logistic regression model\n",
    "pred_lab=lr.predict(X_test_pca) # Test on the test data\n",
    "print(\"Accuracy on test is = %f\" % (100 * accuracy_score(y_test, pred_lab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the decision region on training features and test labels using classifier you have trained above\n",
    "\n",
    "plot_decision_regions(X_train_pca, y_train, classifier=lr)\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.subplots_adjust()\n",
    "#plt.tight_layout()\n",
    "plt.title('Plot on the data')\n",
    "plt.savefig('TRAIN_CLASS.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot the decision region on test features and true labels using classifier you have trained above\n",
    "plot_decision_regions(X_test_pca, y_test, classifier=lr)\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.tight_layout()\n",
    "plt.title('Plot on the test (true) data')\n",
    "plt.savefig('TEST_CLASS_TRUE.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Plot the decision region on test features and predicted labels using classifier you have trained above\n",
    "plot_decision_regions(X_test_pca, pred_lab, classifier=lr)\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower left')\n",
    "plt.title('Plot on the test (predicted) labels')\n",
    "plt.tight_layout()\n",
    "plt.savefig('TEST_CLASS.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
